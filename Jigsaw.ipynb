{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='lightblue'>\n",
    "Information Retrieval Project - Jigsaw Rate Severity of Toxic Comments\n",
    "\n",
    "MohammadReza \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_to_score = pd.read_csv('./datasets/comments_to_score.csv')\n",
    "leaderboard = pd.read_csv('./datasets/leaderboard.csv')\n",
    "sample_submission = pd.read_csv('./datasets/sample_submission.csv')\n",
    "validation_data = pd.read_csv('./datasets/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = validation_data['less_toxic'].iloc[9]\n",
    "# t2 = validation_data['more_toxic'].iloc[9]\n",
    "\n",
    "# determine_severity_toxicity(22, t1)\n",
    "# determine_severity_toxicity(22, t2)\n",
    "\n",
    "# print(model.predict(t1))\n",
    "# print(model.predict(t2))\n",
    "\n",
    "# print('\\n\\n',t1)\n",
    "# print('\\n----\\n', t2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='lightgreen'> Detoxify library</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279ac607f6c14b45b9fc8f94f13ed8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\Anaconda - File\\installed\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Mohammadreza\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33111fe874448cf88303d9c6397e227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae23e9d1ccb4d3dab506ae2c68c2d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import detoxify\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = detoxify.Detoxify('original')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='yellow'>1. Detect_toxicity </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_toxicity(text):\n",
    "    possibility_labels = model.predict(text)\n",
    "    return sum(possibility_labels.values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='yellow'>2. Analyze_intent </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.452, 'neu': 0.548, 'pos': 0.0, 'compound': -0.5106}\n"
     ]
    }
   ],
   "source": [
    "# Exapmle:\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "# Create a SentimentIntensityAnalyzer object\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "sentiment_scores = sid.polarity_scores('you are idiot black asshole')\n",
    "# sentiment_scores = sid.polarity_scores('I love  you')\n",
    "print(sentiment_scores)  # 'compound': -0.5106 _ it's negative, therefore we use asb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_intent(text):\n",
    "    # Get the sentiment scores\n",
    "    sentiment_scores = sid.polarity_scores(text)\n",
    "    return sentiment_scores['neg']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='yellow'>3. Count_toxic_words </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('toxic_words.txt', 'r') as f:\n",
    "    toxic_words = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_toxic_words(text):\n",
    "    count = 0\n",
    "    seen_words = []\n",
    "    for word in text.split():\n",
    "        if word in toxic_words and word not in seen_words:\n",
    "            count += 0.01\n",
    "            seen_words.append(word)\n",
    "        elif word in toxic_words and word in seen_words:\n",
    "            count += 0.0\n",
    "    return count\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='yellow'> Preprocess </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]',' ', text)\n",
    "################################################################################################\n",
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "################################################################################################\n",
    "def remove_numbers(text):\n",
    "    res = ''\n",
    "    for char in text:\n",
    "     if not char.isdigit():\n",
    "          res += char\n",
    "          \n",
    "    return res\n",
    "\n",
    "################################################################################################\n",
    "with open('stopwords.txt', 'r') as stopwords_file:\n",
    "    stopwords = stopwords_file.read().split()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # Tokenize the input text\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove the stop words\n",
    "    filtered_text = [word for word in word_tokens if not word in stopwords]\n",
    "\n",
    "    # Join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_text)\n",
    "    \n",
    "    return filtered_text\n",
    "\n",
    "################################################################################################\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "################################################################################################\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_to_score_temp = comments_to_score.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_to_score_temp['text'] = comments_to_score_temp['text'].apply(remove_punctuation)\n",
    "comments_to_score_temp['text'] = comments_to_score_temp['text'].apply(lower_case)\n",
    "comments_to_score_temp['text'] = comments_to_score_temp['text'].apply(remove_numbers)\n",
    "comments_to_score_temp['text'] = comments_to_score_temp['text'].apply(remove_stopwords)\n",
    "comments_to_score_temp['text'] = comments_to_score_temp['text'].apply(tokenize)\n",
    "comments_to_score_temp['text'] = comments_to_score_temp['text'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = lambda tokens: [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = remove_punctuation(text)\n",
    "    text = lower_case(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = tokenize(text)\n",
    "    text = lemma(text)\n",
    "    # Join the filtered words back into a string\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toxicity(token):\n",
    "    return model.predict(token)['toxicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_toxic_words():\n",
    "    tokens = []\n",
    "    for i, row in comments_to_score_temp.iterrows():\n",
    "        tokens.extend(row['text'])\n",
    "        \n",
    "    tokens = list(set(tokens))\n",
    "    \n",
    "    toxic_words = []\n",
    "    for token in tokens:\n",
    "        if toxicity(token) >= 0.20:\n",
    "            toxic_words.append(token)\n",
    "    \n",
    "    return toxic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_words = find_toxic_words()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1818\n"
     ]
    }
   ],
   "source": [
    "print(len(toxic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write toxic_words list to file\n",
    "with open('toxic_words.txt', 'w') as fp:\n",
    "    for tw in toxic_words:\n",
    "        fp.write(tw + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('toxic_words.txt', 'r') as f:\n",
    "    toxic_words = f.read().split()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='yellow'> determine_severity_toxicity </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_score = []\n",
    "def determine_severity_toxicity(c_id, text):\n",
    "    # global comment_id, comment_score\n",
    "    global comment_score\n",
    "    \n",
    "    # Criteria 1: Language and Tone\n",
    "    toxicity_score = detect_toxicity(text)\n",
    "\n",
    "    # Criteria 2: Intent\n",
    "    intent_score = analyze_intent(text)\n",
    "\n",
    "    # Criteria 3: Frequency and Consistency\n",
    "    toxic_words_count = count_toxic_words(preprocess_text(text))\n",
    "\n",
    "    # Calculate an overall toxicity score for each text based on the criteria\n",
    "    overall_score = (toxicity_score + intent_score + toxic_words_count) / 3\n",
    "\n",
    "   \n",
    "    comment_score.append((c_id, overall_score))\n",
    "    # print(c_id, '  score: ', overall_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='yellow'>Calling determine_severity_toxicity: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in comments_to_score.iterrows():\n",
    "    determine_severity_toxicity(row['comment_id'], row['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>0.023445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>0.059164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>0.019165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>0.034741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>0.185361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15069</th>\n",
       "      <td>504235362</td>\n",
       "      <td>0.314145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15070</th>\n",
       "      <td>504235566</td>\n",
       "      <td>0.024135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <td>504308177</td>\n",
       "      <td>0.074069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15072</th>\n",
       "      <td>504570375</td>\n",
       "      <td>0.765043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15073</th>\n",
       "      <td>504598250</td>\n",
       "      <td>0.058079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15074 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       comment_id     score\n",
       "0          114890  0.023445\n",
       "1          732895  0.059164\n",
       "2         1139051  0.019165\n",
       "3         1434512  0.034741\n",
       "4         2084821  0.185361\n",
       "...           ...       ...\n",
       "15069   504235362  0.314145\n",
       "15070   504235566  0.024135\n",
       "15071   504308177  0.074069\n",
       "15072   504570375  0.765043\n",
       "15073   504598250  0.058079\n",
       "\n",
       "[15074 rows x 2 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_score_final = pd.DataFrame(comment_score, columns=['comment_id', 'score'])\n",
    "comment_score_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14625</th>\n",
       "      <td>459378692</td>\n",
       "      <td>2.188433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>459378692</td>\n",
       "      <td>2.188433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>28808212</td>\n",
       "      <td>2.008952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>28808212</td>\n",
       "      <td>2.008952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>28807993</td>\n",
       "      <td>1.974345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14769</th>\n",
       "      <td>473244297</td>\n",
       "      <td>0.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12956</th>\n",
       "      <td>316890379</td>\n",
       "      <td>0.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>316890379</td>\n",
       "      <td>0.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13418</th>\n",
       "      <td>349203625</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5881</th>\n",
       "      <td>349203625</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15074 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       comment_id     score\n",
       "14625   459378692  2.188433\n",
       "7088    459378692  2.188433\n",
       "334      28808212  2.008952\n",
       "7871     28808212  2.008952\n",
       "333      28807993  1.974345\n",
       "...           ...       ...\n",
       "14769   473244297  0.000440\n",
       "12956   316890379  0.000440\n",
       "5419    316890379  0.000440\n",
       "13418   349203625  0.000438\n",
       "5881    349203625  0.000438\n",
       "\n",
       "[15074 rows x 2 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_score_final = comment_score_final.sort_values(by='score', ascending=False)\n",
    "comment_score_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_score_final.to_csv('comment_score_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>459378692</td>\n",
       "      <td>2.188433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>459378692</td>\n",
       "      <td>2.188433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28808212</td>\n",
       "      <td>2.008952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28808212</td>\n",
       "      <td>2.008952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28807993</td>\n",
       "      <td>1.974345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15069</th>\n",
       "      <td>473244297</td>\n",
       "      <td>0.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15070</th>\n",
       "      <td>316890379</td>\n",
       "      <td>0.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <td>316890379</td>\n",
       "      <td>0.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15072</th>\n",
       "      <td>349203625</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15073</th>\n",
       "      <td>349203625</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15074 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       comment_id     score\n",
       "0       459378692  2.188433\n",
       "1       459378692  2.188433\n",
       "2        28808212  2.008952\n",
       "3        28808212  2.008952\n",
       "4        28807993  1.974345\n",
       "...           ...       ...\n",
       "15069   473244297  0.000440\n",
       "15070   316890379  0.000440\n",
       "15071   316890379  0.000440\n",
       "15072   349203625  0.000438\n",
       "15073   349203625  0.000438\n",
       "\n",
       "[15074 rows x 2 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('comment_score_final.csv')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='lightblue'>Finish</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
